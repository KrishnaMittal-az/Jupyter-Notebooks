{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Notes are saved in Notion <br>\n",
    "The notes are saved in notion under the Class Notes tab and under the Introduction to Machine Learning tab in Lecture - 3 page."
   ],
   "id": "5f07a5d104353d74"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-03T04:50:46.530207Z",
     "start_time": "2024-09-03T04:50:45.738231Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyexpat import features"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Splitting<br>\n",
    "1.Training<br>\n",
    "2.Testing<br>\n",
    "3.Validating<br>\n",
    "\n",
    "First two steps are for developement<br>\n",
    "And the third step is for Accuracy measurement"
   ],
   "id": "871dddb738ffcffb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T05:01:58.142950Z",
     "start_time": "2024-09-03T05:01:58.133367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = {\"Name\" : [\"Ram\" , \"Rohit\" , \"Ravi\" , \"Riya\" , \"Radhe\" , \"Siya\" , \"Vrinda\"] , \n",
    "        \"CPI\" : [8,9,5,7,9,6,9] , \n",
    "        \"Placement\" : [1,0,1,0,1,0,1]}"
   ],
   "id": "1f63db2ff78ccfa6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T05:01:59.249355Z",
     "start_time": "2024-09-03T05:01:59.217485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data1 = pd.DataFrame(data)\n",
    "print(data1)"
   ],
   "id": "c4d536a6c06d01e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  CPI  Placement\n",
      "0     Ram    8          1\n",
      "1   Rohit    9          0\n",
      "2    Ravi    5          1\n",
      "3    Riya    7          0\n",
      "4   Radhe    9          1\n",
      "5    Siya    6          0\n",
      "6  Vrinda    9          1\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T05:03:51.927689Z",
     "start_time": "2024-09-03T05:03:51.907945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = data1[[\"Name\" , \"CPI\" ]]\n",
    "y = data1[[\"Placement\"]]\n",
    " "
   ],
   "id": "aa47406c9fb96a6c",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T05:04:00.721732Z",
     "start_time": "2024-09-03T05:03:59.368887Z"
    }
   },
   "cell_type": "code",
   "source": "from sklearn.model_selection import train_test_split",
   "id": "868a2b469e131415",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
   "id": "ead0589ee3d80fca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " x_train - Training features<br>\n",
    " y_train - Training targets<br>\n",
    " x_test = Testing features<br>\n",
    " y_test - Testing targets<br>\n",
    " "
   ],
   "id": "723bb830052c0d92"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T05:14:01.559107Z",
     "start_time": "2024-09-03T05:14:01.527176Z"
    }
   },
   "cell_type": "code",
   "source": "print(x_train)",
   "id": "37955afc1bebd093",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  CPI\n",
      "1  Rohit    9\n",
      "3   Riya    7\n",
      "0    Ram    8\n",
      "5   Siya    6\n",
      "4  Radhe    9\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T05:14:12.698742Z",
     "start_time": "2024-09-03T05:14:12.688066Z"
    }
   },
   "cell_type": "code",
   "source": "print(x_test)",
   "id": "d43d9773fa26e8d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  CPI\n",
      "6  Vrinda    9\n",
      "2    Ravi    5\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T05:14:20.809878Z",
     "start_time": "2024-09-03T05:14:20.791871Z"
    }
   },
   "cell_type": "code",
   "source": "print(y_train)",
   "id": "f35cd6597f710284",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Placement\n",
      "1          0\n",
      "3          0\n",
      "0          1\n",
      "5          0\n",
      "4          1\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T05:14:28.401108Z",
     "start_time": "2024-09-03T05:14:28.387845Z"
    }
   },
   "cell_type": "code",
   "source": "print(y_test)",
   "id": "51275b2f3d7911f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Placement\n",
      "6          1\n",
      "2          1\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T06:09:12.689301Z",
     "start_time": "2024-09-03T06:09:12.483087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pl = pd.read_csv(\"CSV/Salary_Data.csv\")\n",
    "print(pl)"
   ],
   "id": "1d9a3e872855e09c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Age  Gender    Education Level              Job Title  \\\n",
      "0     32.0    Male         Bachelor's      Software Engineer   \n",
      "1     28.0  Female           Master's           Data Analyst   \n",
      "2     45.0    Male                PhD         Senior Manager   \n",
      "3     36.0  Female         Bachelor's        Sales Associate   \n",
      "4     52.0    Male           Master's               Director   \n",
      "...    ...     ...                ...                    ...   \n",
      "6699  49.0  Female                PhD  Director of Marketing   \n",
      "6700  32.0    Male        High School        Sales Associate   \n",
      "6701  30.0  Female  Bachelor's Degree      Financial Manager   \n",
      "6702  46.0    Male    Master's Degree      Marketing Manager   \n",
      "6703  26.0  Female        High School        Sales Executive   \n",
      "\n",
      "      Years of Experience    Salary  \n",
      "0                     5.0   90000.0  \n",
      "1                     3.0   65000.0  \n",
      "2                    15.0  150000.0  \n",
      "3                     7.0   60000.0  \n",
      "4                    20.0  200000.0  \n",
      "...                   ...       ...  \n",
      "6699                 20.0  200000.0  \n",
      "6700                  3.0   50000.0  \n",
      "6701                  4.0   55000.0  \n",
      "6702                 14.0  140000.0  \n",
      "6703                  1.0   35000.0  \n",
      "\n",
      "[6704 rows x 6 columns]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T06:09:30.889874Z",
     "start_time": "2024-09-03T06:09:30.877397Z"
    }
   },
   "cell_type": "code",
   "source": "print(pl.head())",
   "id": "c83f12375057f4cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age  Gender Education Level          Job Title  Years of Experience  \\\n",
      "0  32.0    Male      Bachelor's  Software Engineer                  5.0   \n",
      "1  28.0  Female        Master's       Data Analyst                  3.0   \n",
      "2  45.0    Male             PhD     Senior Manager                 15.0   \n",
      "3  36.0  Female      Bachelor's    Sales Associate                  7.0   \n",
      "4  52.0    Male        Master's           Director                 20.0   \n",
      "\n",
      "     Salary  \n",
      "0   90000.0  \n",
      "1   65000.0  \n",
      "2  150000.0  \n",
      "3   60000.0  \n",
      "4  200000.0  \n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T06:17:02.359148Z",
     "start_time": "2024-09-03T06:17:02.353320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ],
   "id": "6d6092f02a8f793a",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T06:17:44.869281Z",
     "start_time": "2024-09-03T06:17:44.837172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame(pl)\n",
    "print(df)\n"
   ],
   "id": "e7f40a01d480c57a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Age  Gender    Education Level              Job Title  \\\n",
      "0     32.0    Male         Bachelor's      Software Engineer   \n",
      "1     28.0  Female           Master's           Data Analyst   \n",
      "2     45.0    Male                PhD         Senior Manager   \n",
      "3     36.0  Female         Bachelor's        Sales Associate   \n",
      "4     52.0    Male           Master's               Director   \n",
      "...    ...     ...                ...                    ...   \n",
      "6699  49.0  Female                PhD  Director of Marketing   \n",
      "6700  32.0    Male        High School        Sales Associate   \n",
      "6701  30.0  Female  Bachelor's Degree      Financial Manager   \n",
      "6702  46.0    Male    Master's Degree      Marketing Manager   \n",
      "6703  26.0  Female        High School        Sales Executive   \n",
      "\n",
      "      Years of Experience    Salary  \n",
      "0                     5.0   90000.0  \n",
      "1                     3.0   65000.0  \n",
      "2                    15.0  150000.0  \n",
      "3                     7.0   60000.0  \n",
      "4                    20.0  200000.0  \n",
      "...                   ...       ...  \n",
      "6699                 20.0  200000.0  \n",
      "6700                  3.0   50000.0  \n",
      "6701                  4.0   55000.0  \n",
      "6702                 14.0  140000.0  \n",
      "6703                  1.0   35000.0  \n",
      "\n",
      "[6704 rows x 6 columns]\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T06:18:40.052856Z",
     "start_time": "2024-09-03T06:18:39.975414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = df[[\"Years of Experience\"]]\n",
    "Y = df[[\"Salary\"]]"
   ],
   "id": "dcbff4037d158ff5",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T06:18:43.965191Z",
     "start_time": "2024-09-03T06:18:43.906432Z"
    }
   },
   "cell_type": "code",
   "source": "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)",
   "id": "5e44b67287ba0ac7",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T06:19:39.044716Z",
     "start_time": "2024-09-03T06:19:39.019785Z"
    }
   },
   "cell_type": "code",
   "source": "print(x_train)",
   "id": "3bc2fe6a4b09bfe9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Years of Experience\n",
      "5420                 11.0\n",
      "3757                 18.0\n",
      "4739                  1.0\n",
      "6134                 14.0\n",
      "4203                  6.0\n",
      "...                   ...\n",
      "4931                  9.0\n",
      "3264                  2.0\n",
      "1653                 12.0\n",
      "2607                 30.0\n",
      "2732                 11.0\n",
      "\n",
      "[5363 rows x 1 columns]\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T06:19:43.618291Z",
     "start_time": "2024-09-03T06:19:43.609441Z"
    }
   },
   "cell_type": "code",
   "source": "print(x_test)",
   "id": "1c32156613a71e34",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Years of Experience\n",
      "119                  10.0\n",
      "2805                 13.0\n",
      "3709                  2.0\n",
      "4762                  3.0\n",
      "98                   10.0\n",
      "...                   ...\n",
      "2303                  3.0\n",
      "6669                 19.0\n",
      "899                  11.0\n",
      "6354                 12.0\n",
      "3150                 12.0\n",
      "\n",
      "[1341 rows x 1 columns]\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T06:19:58.852808Z",
     "start_time": "2024-09-03T06:19:58.834761Z"
    }
   },
   "cell_type": "code",
   "source": "print(y_train)",
   "id": "e0d47ee881c40147",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Salary\n",
      "5420  160000.0\n",
      "3757  180000.0\n",
      "4739   30000.0\n",
      "6134  185000.0\n",
      "4203   85000.0\n",
      "...        ...\n",
      "4931  140000.0\n",
      "3264   60000.0\n",
      "1653  170000.0\n",
      "2607  183020.0\n",
      "2732  160000.0\n",
      "\n",
      "[5363 rows x 1 columns]\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T06:20:04.962369Z",
     "start_time": "2024-09-03T06:20:04.948497Z"
    }
   },
   "cell_type": "code",
   "source": "print(y_test)",
   "id": "d4e45c44487aa4d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Salary\n",
      "119   120000.0\n",
      "2805  140010.0\n",
      "3709   35000.0\n",
      "4762   52000.0\n",
      "98     90000.0\n",
      "...        ...\n",
      "2303   70000.0\n",
      "6669  190000.0\n",
      "899   198000.0\n",
      "6354  120000.0\n",
      "3150  170000.0\n",
      "\n",
      "[1341 rows x 1 columns]\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T08:36:31.599033Z",
     "start_time": "2024-09-03T08:36:31.497115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# df.dropna()\n",
    "df = df.fillna(df.mean())"
   ],
   "id": "a6b71889838ee3e7",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[34], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# df.dropna()\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mfillna(df\u001B[38;5;241m.\u001B[39mmean())\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11693\u001B[0m, in \u001B[0;36mDataFrame.mean\u001B[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001B[0m\n\u001B[0;32m  11685\u001B[0m \u001B[38;5;129m@doc\u001B[39m(make_doc(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m\"\u001B[39m, ndim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m))\n\u001B[0;32m  11686\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmean\u001B[39m(\n\u001B[0;32m  11687\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m  11691\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m  11692\u001B[0m ):\n\u001B[1;32m> 11693\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mmean(axis, skipna, numeric_only, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m  11694\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(result, Series):\n\u001B[0;32m  11695\u001B[0m         result \u001B[38;5;241m=\u001B[39m result\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12420\u001B[0m, in \u001B[0;36mNDFrame.mean\u001B[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001B[0m\n\u001B[0;32m  12413\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmean\u001B[39m(\n\u001B[0;32m  12414\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m  12415\u001B[0m     axis: Axis \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m  12418\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m  12419\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Series \u001B[38;5;241m|\u001B[39m \u001B[38;5;28mfloat\u001B[39m:\n\u001B[1;32m> 12420\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stat_function(\n\u001B[0;32m  12421\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m\"\u001B[39m, nanops\u001B[38;5;241m.\u001B[39mnanmean, axis, skipna, numeric_only, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m  12422\u001B[0m     )\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12377\u001B[0m, in \u001B[0;36mNDFrame._stat_function\u001B[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001B[0m\n\u001B[0;32m  12373\u001B[0m nv\u001B[38;5;241m.\u001B[39mvalidate_func(name, (), kwargs)\n\u001B[0;32m  12375\u001B[0m validate_bool_kwarg(skipna, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskipna\u001B[39m\u001B[38;5;124m\"\u001B[39m, none_allowed\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m> 12377\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reduce(\n\u001B[0;32m  12378\u001B[0m     func, name\u001B[38;5;241m=\u001B[39mname, axis\u001B[38;5;241m=\u001B[39maxis, skipna\u001B[38;5;241m=\u001B[39mskipna, numeric_only\u001B[38;5;241m=\u001B[39mnumeric_only\n\u001B[0;32m  12379\u001B[0m )\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11562\u001B[0m, in \u001B[0;36mDataFrame._reduce\u001B[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001B[0m\n\u001B[0;32m  11558\u001B[0m     df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mT\n\u001B[0;32m  11560\u001B[0m \u001B[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001B[39;00m\n\u001B[0;32m  11561\u001B[0m \u001B[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001B[39;00m\n\u001B[1;32m> 11562\u001B[0m res \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39m_mgr\u001B[38;5;241m.\u001B[39mreduce(blk_func)\n\u001B[0;32m  11563\u001B[0m out \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39m_constructor_from_mgr(res, axes\u001B[38;5;241m=\u001B[39mres\u001B[38;5;241m.\u001B[39maxes)\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m  11564\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m out_dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m out\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mboolean\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1500\u001B[0m, in \u001B[0;36mBlockManager.reduce\u001B[1;34m(self, func)\u001B[0m\n\u001B[0;32m   1498\u001B[0m res_blocks: \u001B[38;5;28mlist\u001B[39m[Block] \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m   1499\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m blk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblocks:\n\u001B[1;32m-> 1500\u001B[0m     nbs \u001B[38;5;241m=\u001B[39m blk\u001B[38;5;241m.\u001B[39mreduce(func)\n\u001B[0;32m   1501\u001B[0m     res_blocks\u001B[38;5;241m.\u001B[39mextend(nbs)\n\u001B[0;32m   1503\u001B[0m index \u001B[38;5;241m=\u001B[39m Index([\u001B[38;5;28;01mNone\u001B[39;00m])  \u001B[38;5;66;03m# placeholder\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:404\u001B[0m, in \u001B[0;36mBlock.reduce\u001B[1;34m(self, func)\u001B[0m\n\u001B[0;32m    398\u001B[0m \u001B[38;5;129m@final\u001B[39m\n\u001B[0;32m    399\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mreduce\u001B[39m(\u001B[38;5;28mself\u001B[39m, func) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlist\u001B[39m[Block]:\n\u001B[0;32m    400\u001B[0m     \u001B[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001B[39;00m\n\u001B[0;32m    401\u001B[0m     \u001B[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001B[39;00m\n\u001B[0;32m    402\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[1;32m--> 404\u001B[0m     result \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalues)\n\u001B[0;32m    406\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    407\u001B[0m         res_values \u001B[38;5;241m=\u001B[39m result\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11481\u001B[0m, in \u001B[0;36mDataFrame._reduce.<locals>.blk_func\u001B[1;34m(values, axis)\u001B[0m\n\u001B[0;32m  11479\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray([result])\n\u001B[0;32m  11480\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m> 11481\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m op(values, axis\u001B[38;5;241m=\u001B[39maxis, skipna\u001B[38;5;241m=\u001B[39mskipna, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:147\u001B[0m, in \u001B[0;36mbottleneck_switch.__call__.<locals>.f\u001B[1;34m(values, axis, skipna, **kwds)\u001B[0m\n\u001B[0;32m    145\u001B[0m         result \u001B[38;5;241m=\u001B[39m alt(values, axis\u001B[38;5;241m=\u001B[39maxis, skipna\u001B[38;5;241m=\u001B[39mskipna, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    146\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 147\u001B[0m     result \u001B[38;5;241m=\u001B[39m alt(values, axis\u001B[38;5;241m=\u001B[39maxis, skipna\u001B[38;5;241m=\u001B[39mskipna, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:404\u001B[0m, in \u001B[0;36m_datetimelike_compat.<locals>.new_func\u001B[1;34m(values, axis, skipna, mask, **kwargs)\u001B[0m\n\u001B[0;32m    401\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m datetimelike \u001B[38;5;129;01mand\u001B[39;00m mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    402\u001B[0m     mask \u001B[38;5;241m=\u001B[39m isna(values)\n\u001B[1;32m--> 404\u001B[0m result \u001B[38;5;241m=\u001B[39m func(values, axis\u001B[38;5;241m=\u001B[39maxis, skipna\u001B[38;5;241m=\u001B[39mskipna, mask\u001B[38;5;241m=\u001B[39mmask, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    406\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m datetimelike:\n\u001B[0;32m    407\u001B[0m     result \u001B[38;5;241m=\u001B[39m _wrap_results(result, orig_values\u001B[38;5;241m.\u001B[39mdtype, fill_value\u001B[38;5;241m=\u001B[39miNaT)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:719\u001B[0m, in \u001B[0;36mnanmean\u001B[1;34m(values, axis, skipna, mask)\u001B[0m\n\u001B[0;32m    716\u001B[0m     dtype_count \u001B[38;5;241m=\u001B[39m dtype\n\u001B[0;32m    718\u001B[0m count \u001B[38;5;241m=\u001B[39m _get_counts(values\u001B[38;5;241m.\u001B[39mshape, mask, axis, dtype\u001B[38;5;241m=\u001B[39mdtype_count)\n\u001B[1;32m--> 719\u001B[0m the_sum \u001B[38;5;241m=\u001B[39m values\u001B[38;5;241m.\u001B[39msum(axis, dtype\u001B[38;5;241m=\u001B[39mdtype_sum)\n\u001B[0;32m    720\u001B[0m the_sum \u001B[38;5;241m=\u001B[39m _ensure_numeric(the_sum)\n\u001B[0;32m    722\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m axis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(the_sum, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mndim\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:49\u001B[0m, in \u001B[0;36m_sum\u001B[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_sum\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m     48\u001B[0m          initial\u001B[38;5;241m=\u001B[39m_NoValue, where\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m---> 49\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "\u001B[1;31mTypeError\u001B[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T06:25:30.756532Z",
     "start_time": "2024-09-03T06:25:30.669182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)"
   ],
   "id": "81ebdde63a8f6cc9",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[32], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m LinearRegression()\n\u001B[1;32m----> 2\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(x_train, y_train)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1471\u001B[0m     )\n\u001B[0;32m   1472\u001B[0m ):\n\u001B[1;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:609\u001B[0m, in \u001B[0;36mLinearRegression.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    605\u001B[0m n_jobs_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_jobs\n\u001B[0;32m    607\u001B[0m accept_sparse \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpositive \u001B[38;5;28;01melse\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsr\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsc\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcoo\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m--> 609\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_data(\n\u001B[0;32m    610\u001B[0m     X,\n\u001B[0;32m    611\u001B[0m     y,\n\u001B[0;32m    612\u001B[0m     accept_sparse\u001B[38;5;241m=\u001B[39maccept_sparse,\n\u001B[0;32m    613\u001B[0m     y_numeric\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    614\u001B[0m     multi_output\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    615\u001B[0m     force_writeable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    616\u001B[0m )\n\u001B[0;32m    618\u001B[0m has_sw \u001B[38;5;241m=\u001B[39m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    619\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_sw:\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\base.py:650\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[0;32m    648\u001B[0m         y \u001B[38;5;241m=\u001B[39m check_array(y, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params)\n\u001B[0;32m    649\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 650\u001B[0m         X, y \u001B[38;5;241m=\u001B[39m check_X_y(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n\u001B[0;32m    651\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[0;32m    653\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1301\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[0;32m   1296\u001B[0m         estimator_name \u001B[38;5;241m=\u001B[39m _check_estimator_name(estimator)\n\u001B[0;32m   1297\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1298\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires y to be passed, but the target y is None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1299\u001B[0m     )\n\u001B[1;32m-> 1301\u001B[0m X \u001B[38;5;241m=\u001B[39m check_array(\n\u001B[0;32m   1302\u001B[0m     X,\n\u001B[0;32m   1303\u001B[0m     accept_sparse\u001B[38;5;241m=\u001B[39maccept_sparse,\n\u001B[0;32m   1304\u001B[0m     accept_large_sparse\u001B[38;5;241m=\u001B[39maccept_large_sparse,\n\u001B[0;32m   1305\u001B[0m     dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[0;32m   1306\u001B[0m     order\u001B[38;5;241m=\u001B[39morder,\n\u001B[0;32m   1307\u001B[0m     copy\u001B[38;5;241m=\u001B[39mcopy,\n\u001B[0;32m   1308\u001B[0m     force_writeable\u001B[38;5;241m=\u001B[39mforce_writeable,\n\u001B[0;32m   1309\u001B[0m     force_all_finite\u001B[38;5;241m=\u001B[39mforce_all_finite,\n\u001B[0;32m   1310\u001B[0m     ensure_2d\u001B[38;5;241m=\u001B[39mensure_2d,\n\u001B[0;32m   1311\u001B[0m     allow_nd\u001B[38;5;241m=\u001B[39mallow_nd,\n\u001B[0;32m   1312\u001B[0m     ensure_min_samples\u001B[38;5;241m=\u001B[39mensure_min_samples,\n\u001B[0;32m   1313\u001B[0m     ensure_min_features\u001B[38;5;241m=\u001B[39mensure_min_features,\n\u001B[0;32m   1314\u001B[0m     estimator\u001B[38;5;241m=\u001B[39mestimator,\n\u001B[0;32m   1315\u001B[0m     input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1316\u001B[0m )\n\u001B[0;32m   1318\u001B[0m y \u001B[38;5;241m=\u001B[39m _check_y(y, multi_output\u001B[38;5;241m=\u001B[39mmulti_output, y_numeric\u001B[38;5;241m=\u001B[39my_numeric, estimator\u001B[38;5;241m=\u001B[39mestimator)\n\u001B[0;32m   1320\u001B[0m check_consistent_length(X, y)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1064\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m   1058\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1059\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m expected <= 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1060\u001B[0m         \u001B[38;5;241m%\u001B[39m (array\u001B[38;5;241m.\u001B[39mndim, estimator_name)\n\u001B[0;32m   1061\u001B[0m     )\n\u001B[0;32m   1063\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n\u001B[1;32m-> 1064\u001B[0m     _assert_all_finite(\n\u001B[0;32m   1065\u001B[0m         array,\n\u001B[0;32m   1066\u001B[0m         input_name\u001B[38;5;241m=\u001B[39minput_name,\n\u001B[0;32m   1067\u001B[0m         estimator_name\u001B[38;5;241m=\u001B[39mestimator_name,\n\u001B[0;32m   1068\u001B[0m         allow_nan\u001B[38;5;241m=\u001B[39mforce_all_finite \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow-nan\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1069\u001B[0m     )\n\u001B[0;32m   1071\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copy:\n\u001B[0;32m   1072\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_numpy_namespace(xp):\n\u001B[0;32m   1073\u001B[0m         \u001B[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:123\u001B[0m, in \u001B[0;36m_assert_all_finite\u001B[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m first_pass_isfinite:\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m--> 123\u001B[0m _assert_all_finite_element_wise(\n\u001B[0;32m    124\u001B[0m     X,\n\u001B[0;32m    125\u001B[0m     xp\u001B[38;5;241m=\u001B[39mxp,\n\u001B[0;32m    126\u001B[0m     allow_nan\u001B[38;5;241m=\u001B[39mallow_nan,\n\u001B[0;32m    127\u001B[0m     msg_dtype\u001B[38;5;241m=\u001B[39mmsg_dtype,\n\u001B[0;32m    128\u001B[0m     estimator_name\u001B[38;5;241m=\u001B[39mestimator_name,\n\u001B[0;32m    129\u001B[0m     input_name\u001B[38;5;241m=\u001B[39minput_name,\n\u001B[0;32m    130\u001B[0m )\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:172\u001B[0m, in \u001B[0;36m_assert_all_finite_element_wise\u001B[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[0;32m    155\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m estimator_name \u001B[38;5;129;01mand\u001B[39;00m input_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m has_nan_error:\n\u001B[0;32m    156\u001B[0m     \u001B[38;5;66;03m# Improve the error message on how to handle missing values in\u001B[39;00m\n\u001B[0;32m    157\u001B[0m     \u001B[38;5;66;03m# scikit-learn.\u001B[39;00m\n\u001B[0;32m    158\u001B[0m     msg_err \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    159\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not accept missing values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    160\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    170\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#estimators-that-handle-nan-values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    171\u001B[0m     )\n\u001B[1;32m--> 172\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg_err)\n",
      "\u001B[1;31mValueError\u001B[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ac6869a165950f45"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
